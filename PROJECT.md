# ğŸ¯ PROJECT.md â€” API VLR.GG Scraper

> DerniÃ¨re mise Ã  jour : 2025-05-08 17:39:35 UTC

---

## ğŸ§¾ Description rapide

API personnelle qui rÃ©cupÃ¨re les donnÃ©es des matchs de Valorant depuis **vlr.gg** via scraping, les stocke en base de donnÃ©es SQLite, et les expose via **FastAPI**.

---

## ğŸ§± Structure actuelle

### ğŸ“ Endpoints :

- `GET /match/{id}`  
  âœ Retourne les infos dâ€™un match donnÃ©. Scrape si non trouvÃ© en BDD.

### ğŸ“¦ Base de donnÃ©es :

- `Match` et `MatchDetails` : stockent les infos principales
- `updated_at` : permet de savoir quand la donnÃ©e a Ã©tÃ© insÃ©rÃ©e ou mise Ã  jour
- `status` (prÃ©vu) : indique l'Ã©tat du match (Ã  venir, en cours, terminÃ©)

### ğŸ›  Scrapers :

- `get_match_data(id)` : scrape les dÃ©tails dâ€™un match
- `get_match_list()` : (dÃ©jÃ  prÃ©sent mais Ã  Ã©tendre)

---

## âœ… Ce qui fonctionne actuellement

- [x] Scraper de match par ID opÃ©rationnel
- [x] Insertion SQLAlchemy en BDD
- [x] Endpoint `/match/<built-in function id>` fonctionnel avec fallback sur scraper
- [x] Champ `updated_at` ajoutÃ© et utilisÃ©
- [x] Suppression du script manuel `add_match_details.py`

---

## ğŸ”œ TÃ¢ches Ã  faire / Roadmap

### ğŸ”¹ Logique de mise Ã  jour

- [ ] Ajouter champ `status` dans `MatchDetails`
- [ ] DÃ©terminer `status` dans le scraper (`planned`, `live`, `finished`)
- [ ] Mettre Ã  jour le champ `status` en BDD
- [ ] Ajouter logique de rafraÃ®chissement conditionnel selon :
  - `live` âœ toutes les 1 min
  - `planned` âœ toutes les 15 min
  - `finished` âœ jamais (ou 1x/jour)

### ğŸ”¹ Nouvelles fonctionnalitÃ©s

- [ ] Endpoint `/live` âœ retourne les matchs en cours
- [ ] Endpoint `/schedule` âœ retourne les prochains matchs
- [ ] Endpoint `/results` âœ retourne les derniers rÃ©sultats
- [ ] ParamÃ¨tre `refresh=true` pour forcer un re-scrape

---

## ğŸ’¡ Notes et rÃ©flexions

- âœ” Le status peut souvent Ãªtre dÃ©duit de lâ€™URL de scraping (`/schedule`, `/live`, `/results`)
- â“ Faut-il filtrer les matchs incomplets (ex : 0-0, scores manquants) ?
- â“ Ã€ terme, envisager PostgreSQL ou Mongo pour plus de scalabilitÃ© ?
